{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64ad78ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543236fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cceea998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating directory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data\\\\pizza_steak_sushi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreating directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\pathlib.py:1116\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[1;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1113\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1116\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data\\\\pizza_steak_sushi'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path/\"pizza_steak_sushi\"\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(\"data already downloaded\")\n",
    "else:\n",
    "    print(\"creating directory\")\n",
    "    image_path.mkdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(image_path/\"images.zip\",mode=\"wb\") as f:\n",
    "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "    f.write(request.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d486a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zep_ref = zipfile.ZipFile(image_path/\"images.zip\")\n",
    "zep_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a07db6",
   "metadata": {},
   "source": [
    "### Becoming One with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = image_path/ \"train\"\n",
    "test_dir = image_path/\"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6039bb",
   "metadata": {},
   "source": [
    "### Visualising the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d6f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image # PIL stands for Pillow library!\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68dfa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=[] #list\n",
    "image_train_labels=[]\n",
    "image_train_path_list = list(image_path.glob(\"train/*/*.jpg\"))\n",
    "for i in image_train_path_list:\n",
    "    image = Image.open(i)\n",
    "    image_train_labels.append(i.parent.stem)\n",
    "    train_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655339ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images =[]\n",
    "image_test_path_list = list(image_path.glob(\"test/*/*.jpg\"))\n",
    "image_test_labels =[]\n",
    "for i in image_test_path_list:\n",
    "    image = Image.open(i)\n",
    "    test_images.append(image)\n",
    "    image_class = i.parent.stem\n",
    "    image_test_labels.append(image_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f094b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding all images:\n",
    "import numpy as np\n",
    "def PaddingImagesInList(image_list:list):\n",
    "    padded_images=[]\n",
    "    max_height = max(img.height for img in image_list)\n",
    "    max_width = max(img.width for img in image_list)\n",
    "    print(f\"max_height: {max_height} and max_widht: {max_width}\")\n",
    "    train_np = []\n",
    "    for img in image_list:\n",
    "        padding = (0,0,max_width -img.width,max_height-img.height)\n",
    "        padded_image = ImageOps.expand(img,padding,fill=0)\n",
    "        padded_images.append(padded_image) # fill means black pixels are added\n",
    "    return padded_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4357f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_train_images = PaddingImagesInList(train_images)\n",
    "padded_test_images = PaddingImagesInList(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a527f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(padded_train_images[0])\n",
    "print(image_train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f81240",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_array = np.stack([np.array(img) for img in padded_train_images])\n",
    "test_images_array = np.stack([np.array(img) for img in padded_test_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a88ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_array.shape # 225 elements where elem is 512 widht 512 height 3 colour channel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97328777",
   "metadata": {},
   "source": [
    "### Creating CNN Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771886b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FoodDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FoodDetector,self).__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=100,kernel_size=(2,2),stride=1,padding=1), # inchannels = number of color channels\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=100,out_channels=100,kernel_size=(2,2),stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=100,out_channels=100,kernel_size=(2,2),stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=100,out_channels=100,kernel_size=(2,2),stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.conv_block_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=100,out_channels=200,kernel_size=(3,3),stride=1,padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(), #converts into single feature vector\n",
    "            nn.Linear(in_features=369800, out_features=10)  # Here, change from 64 to 6400\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        x= self.conv_block_3(x)\n",
    "        print(f\"shape: {x.shape}\")\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    #TinyVGG!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809d2464",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_tensor = torch.from_numpy(train_images_array).float()\n",
    "test_images_tensor = torch.from_numpy(test_images_array).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65404b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FoodDetector()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ec22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"shape of image:{train_images_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a56356",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_tensor =(train_images_tensor).permute(0,3,1,2)\n",
    "print(f\"shape of image:{train_images_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e8892",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_index = random.randint(0,len(train_images_tensor))\n",
    "img = train_images_tensor[rand_index]\n",
    "print(f\"shape of image:{img.shape}\")\n",
    "test_images_tensor = (test_images_tensor).permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b73e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_loop:\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb496d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_pred,y_true):\n",
    "    y_pred = torch.argmax(y_pred,dim=1)\n",
    "    acc = torch.eq(y_pred,y_true).sum().item()\n",
    "    acc = acc/len(y_true)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc8d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7803cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f2683",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "image_train_labels = label_encoder.fit_transform(image_train_labels)\n",
    "image_test_labels = label_encoder.transform(image_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e56320",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train_labels_tensor = torch.LongTensor(image_train_labels)\n",
    "image_test_labels_tensor = torch.LongTensor(image_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a66dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_tensor = train_images_tensor.to(device)\n",
    "test_images_tensor = test_images_tensor.to(device)\n",
    "image_train_labels_tensor = image_train_labels_tensor.to(device)\n",
    "image_test_labels_tensor = image_test_labels_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c819cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl_helper = []\n",
    "for i in range(len(train_images_tensor)):\n",
    "    train_dl_helper.append([train_images_tensor[i], image_train_labels_tensor[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e409c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl_helper = []\n",
    "for i in range(len(test_images_tensor)):\n",
    "    test_dl_helper.append([test_images_tensor[i],image_test_labels_tensor[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fca882",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dl_helper, shuffle=True, batch_size=32)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dl_helper, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc10d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "ephocs=10\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007e2ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = 0.0\n",
    "train_acc = 0.0\n",
    "for epoch in tqdm(range(ephocs)):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    for batch,data in enumerate(train_dataloader):\n",
    "        (X,y)=data\n",
    "        y_logits = model(X)\n",
    "        loss = loss_fn(y_logits,y)\n",
    "        train_loss += loss.item()\n",
    "        acc = accuracy_fn(y_true = y,y_pred = y_logits)\n",
    "        train_acc  +=acc\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "       \n",
    "    train_loss = train_loss /len(train_dataloader)\n",
    "    train_acc = train_acc / len(train_dataloader)\n",
    "    print(f\"[Epoch {epoch + 1}] Avg. Loss: {train_loss:.3f}, Avg. Acc: {train_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7acf2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set the model to evaluation mode for testing\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m      4\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      5\u001b[0m test_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode for testing\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "test_acc = 0.0\n",
    "\n",
    "# Disable gradient calculation as it's not needed for inference\n",
    "with torch.no_grad():\n",
    "    for batch, data in enumerate(test_dataloader):\n",
    "        (X, y) = data\n",
    "        y_logits = model(X)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn(y_logits, y)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc = accuracy_fn(y_true=y, y_pred=y_logits)\n",
    "        test_acc += acc\n",
    "\n",
    "# Calculate the average test loss and accuracy\n",
    "test_loss = test_loss / len(test_dataloader)\n",
    "test_acc = test_acc / len(test_dataloader)\n",
    "\n",
    "print(f\"Avg. Test Loss: {test_loss:.3f}, Avg. Test Acc: {test_acc:.3f}\")\n",
    "\n",
    "# Set the model back to training mode\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf973a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
